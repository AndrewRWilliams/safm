_target_: src.policies.mappo.MAPPO
params:
  n_layers: 2
  hidden_dim: 128
  learning_rate: 0.0003
  gamma: 0.99
  gae_lambda: 0.95
  gae: False
  n_agents: ${n_agents}
  ent_coef: 0.01
  vf_coef: 0.5
  norm_adv: True
  clip_coef: 0.2
  clip_vloss: True
  max_grad_norm: 9
  target_kl: null
  update_epochs: 10
  num_minibatches: 1
  rollout_threads: ${rollout_threads}
  env_steps: ${env_steps}
  activation: tanh
  shared_critic: False
  shared_actor: True
  continuous_action: ${continuous_action}